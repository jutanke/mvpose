{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "Settings = json.load(open('../settings.txt'))\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "from cselect import color as cs\n",
    "import sys\n",
    "sys.path.insert(0,'../')\n",
    "sys.path.insert(0,'../samples')\n",
    "from mvpose.data import epfl_campus\n",
    "\n",
    "root = Settings['data_root']\n",
    "root = join(root, 'pak')\n",
    "tmp = Settings['tmp']\n",
    "\n",
    "# FRAME = 800\n",
    "# X, Y, Calib = epfl_campus.get(root, FRAME)\n",
    "\n",
    "# fig = plt.figure(figsize=(16,16))\n",
    "\n",
    "# COLORS = ['red', 'green', 'blue', 'yellow']\n",
    "\n",
    "# for cid in [0, 1, 2]:\n",
    "#     ax = fig.add_subplot(1, 3, cid+1)\n",
    "#     cam = Calib[cid]\n",
    "#     im = X[cid]\n",
    "#     ax.imshow(im)\n",
    "#     ax.axis('off')\n",
    "    \n",
    "#     for pid, person in enumerate(Y):\n",
    "#         pts3d = person\n",
    "#         if pts3d is None:\n",
    "#             continue\n",
    "        \n",
    "#         pts2d = cam.projectPoints(pts3d)\n",
    "#         for u, v in pts2d:\n",
    "#             ax.scatter(u, v, color=COLORS[pid])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation frames:\n",
    "[350 - 470] and [650 - 750]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==================================\n",
    "# from mvpose import pose\n",
    "# from mvpose.algorithm import graphcut\n",
    "# from mvpose.algorithm.settings import get_settings\n",
    "# import paf_loader\n",
    "\n",
    "\n",
    "# FRAME = 350\n",
    "# Im, Y, Calib = epfl_campus.get(root, FRAME)\n",
    "\n",
    "# heatmaps, pafs = paf_loader.load_confidence_map_and_paf('campus', \n",
    "#                                                         Im, \n",
    "#                                                         FRAME, \n",
    "#                                                         dir=tmp)\n",
    "\n",
    "# Debug, detections = pose.estimate(Calib, heatmaps, pafs,\n",
    "#                                   settings=param,\n",
    "#                                   debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: generate HMs and PAFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# Settings = json.load(open('../settings.txt'))\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from os.path import join\n",
    "# from cselect import color as cs\n",
    "# import sys\n",
    "# sys.path.insert(0,'../')\n",
    "# sys.path.insert(0,'../samples')\n",
    "# from mvpose.data import epfl_campus\n",
    "# # ==================================\n",
    "# from mvpose import pose\n",
    "# from mvpose.algorithm import graphcut\n",
    "# from mvpose.algorithm.settings import get_settings\n",
    "# import paf_loader\n",
    "# from mvpose.plot.limbs import draw_mscoco_human\n",
    "\n",
    "# root = Settings['data_root']\n",
    "# root = join(root, 'pak')\n",
    "# tmp = Settings['tmp']\n",
    "\n",
    "# def exec_frame(frame):\n",
    "#     Im, Y, Calib = epfl_campus.get(root, frame)\n",
    "#     heatmaps, pafs = paf_loader.load_confidence_map_and_paf('campus', \n",
    "#                                                         Im,\n",
    "#                                                         frame,\n",
    "#                                                         dir=tmp)\n",
    "#     del Im\n",
    "#     del Y\n",
    "#     del Calib\n",
    "#     del heatmaps\n",
    "#     del pafs\n",
    "\n",
    "\n",
    "# for frame in range(747, 750):\n",
    "#     print('handling frame ', frame)\n",
    "#     exec_frame(frame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: generate candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mvpose import pose\n",
    "from mvpose.algorithm import graphcut\n",
    "from time import time\n",
    "from mvpose import pose\n",
    "from mvpose.algorithm import graphcut\n",
    "from mvpose.algorithm.settings import get_settings\n",
    "import paf_loader\n",
    "\n",
    "# --- Things that kinda have to be parametrized ---\n",
    "candidate_main_name = 'campus_candidates_frame'\n",
    "dict_file = join(tmp, 'campus_scores.npy')\n",
    "params = get_settings(scale_to_mm=1000)\n",
    "# -------------------------------------------------\n",
    "\n",
    "def execute(FRAME):\n",
    "    global params, candidate_main_name\n",
    "    Im, Y, Calib = epfl_campus.get(root, FRAME)\n",
    "    print('\\nframe:', FRAME)\n",
    "    heatmaps, pafs = paf_loader.load_confidence_map_and_paf('campus', \n",
    "                                                            Im, \n",
    "                                                            FRAME, \n",
    "                                                            dir=tmp)\n",
    "    _start = time()\n",
    "    detections = pose.estimate_heuristic(\n",
    "        Calib, heatmaps, pafs, settings=params, \n",
    "        debug=False, use_greedy=False)\n",
    "    _end = time()\n",
    "    print('total elapsed:', _end - _start)\n",
    "    \n",
    "    # -- store to file --\n",
    "    candidate_name = candidate_main_name + str(FRAME) + \".npy\"\n",
    "    candidate_name = join(tmp, candidate_name)\n",
    "    np.save(candidate_name, detections)\n",
    "    \n",
    "    del heatmaps\n",
    "    del pafs\n",
    "    del detections\n",
    "    del Im\n",
    "    del Y\n",
    "    del Calib\n",
    "\n",
    "def run_all():\n",
    "    # 350 - 470 + 650 - 750\n",
    "    for f in range(350, 470):\n",
    "        execute(f)\n",
    "\n",
    "run_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: calculate re-id score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mvpose.algorithm.track_graph_partitioning import get_bb, distance3d_humans, ValidImageCandidateExtractor\n",
    "from mvpose.tracking import extend_calibration_to_frames\n",
    "from os.path import join, isdir, isfile\n",
    "from reid import reid\n",
    "\n",
    "from mvpose.algorithm.settings import get_settings, get_tracking_settings\n",
    "\n",
    "#reid_model = reid.ReId()\n",
    "reid_model = {}  # we can skip this ONLY if we already calc. reid scores!\n",
    "tracking_params = get_tracking_settings(params, \n",
    "                                        low_spec_mode=True, \n",
    "                                        reid_model=reid_model,\n",
    "                                        max_moving_distance_per_frame=1000000,\n",
    "                                        valid_person_bb_area=50,\n",
    "                                        personreid_batchsize=2)\n",
    "\n",
    "valid_frames = list(range(350, 470)) + list(range(650, 750))\n",
    "n_frames = len(valid_frames)\n",
    "graph_3d = {}\n",
    "human_candidates = []\n",
    "Im = []\n",
    "\n",
    "# 350 - 470 + 650 - 750\n",
    "for frame in valid_frames:\n",
    "    if frame % 50 == 0:\n",
    "        print('frame ', frame)\n",
    "    candidate_name = candidate_main_name + str(frame) + \".npy\"\n",
    "    candidate_name = join(tmp, candidate_name)\n",
    "    assert isfile(candidate_name)\n",
    "    Humans = np.load(candidate_name)\n",
    "    human_candidates.append(Humans)\n",
    "    im, Y, Calib = epfl_campus.get(root, frame)\n",
    "    Im.append(im)\n",
    "Im = np.array(Im, 'uint8')\n",
    "\n",
    "print(len(human_candidates))\n",
    "\n",
    "Calibs = extend_calibration_to_frames([Calib], n_frames)\n",
    "\n",
    "img_cand = ValidImageCandidateExtractor(Im, human_candidates, Calibs, tracking_params)\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# n = len(img_cand.ImgsA)\n",
    "# print('n=', n)\n",
    "# start = 0\n",
    "# if isfile(dict_file):\n",
    "#     start = np.load(dict_file).item()['next_frame']\n",
    "\n",
    "# print('start:' + str(start) + ' until ' + str(n))\n",
    "# for frame in range(start, n):\n",
    "#     if isfile(dict_file):\n",
    "#         storage = np.load(dict_file).item()\n",
    "#     else:\n",
    "#         storage = {}\n",
    "    \n",
    "#     if frame % 10 == 0:\n",
    "#         print('frame %05d/' % (frame+1) + str(n))\n",
    "#         _start = time()\n",
    "#     A = img_cand.ImgsA[frame]\n",
    "#     B = img_cand.ImgsB[frame]\n",
    "#     score = np.squeeze(reid_model.predict(A, B))\n",
    "#     #print('storage', storage)\n",
    "#     #print('score', score)\n",
    "#     storage[frame] = score\n",
    "#     storage['next_frame'] = frame + 1\n",
    "#     np.save(dict_file, storage)\n",
    "#     if frame % 10 == 0:\n",
    "#         _end = time()\n",
    "#         print('\\telapsed', _end - _start)\n",
    "#     del storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: build graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mvpose.algorithm.track_graph_partitioning import generate_graph3d, GraphSolver\n",
    "# from mvpose.algorithm.track_graph_partitioning import construct_query_graph\n",
    "# from mvpose.tracking import extract_tracks\n",
    "\n",
    "# storage = np.load(dict_file).item()\n",
    "\n",
    "# scores = []\n",
    "# pairs = img_cand.pairs\n",
    "# n = len(img_cand.ImgsA)\n",
    "# print(n)\n",
    "\n",
    "# assert(len(pairs) == n)\n",
    "# for frame in range(n):\n",
    "#     scores.append(storage[frame])\n",
    "# assert len(scores) == n\n",
    "\n",
    "\n",
    "# graph_3d = generate_graph3d(scores, pairs)  # t1, pid1, t2, pid2\n",
    "\n",
    "# n_frames_red = len(human_candidates)\n",
    "# graph_partitioning = GraphSolver(graph_3d, \n",
    "#                                  n_frames_red,\n",
    "#                                  tracking_params.T)\n",
    "\n",
    "\n",
    "# G = construct_query_graph(graph_partitioning, n_frames_red)\n",
    "\n",
    "# tracks = extract_tracks(human_candidates, G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: PCP for single individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mvpose.evaluation import pcp\n",
    "import mvpose.data.kth_football2 as kth\n",
    "import mvpose.data.skeleton_augmentation as ska\n",
    "model_path = '../data/model_poseprediction.h5'\n",
    "gen = ska.LimbGenerator(model_path, params.scale_to_mm)\n",
    "\n",
    "def generate_pcp_score(frame):\n",
    "    alpha = 0.5\n",
    "    candidate_name = candidate_main_name + str(frame) + \".npy\"\n",
    "    candidate_name = join(tmp, candidate_name)\n",
    "    assert isfile(candidate_name)\n",
    "    candidates = np.load(candidate_name)\n",
    "    #candidates = gen.apply(candidates)\n",
    "    Humans = kth.transform3d_from_mscoco(candidates)\n",
    "    \n",
    "    Im, Y, Calib = epfl_campus.get(root, frame)\n",
    "    \n",
    "    L_Arms = []\n",
    "    U_Arms = []\n",
    "    L_Legs = []\n",
    "    U_Legs = []\n",
    "    Avg = []\n",
    "    GTIDs = []\n",
    "  \n",
    "    for gtid, gt in enumerate(Y):\n",
    "        if gt is None:\n",
    "            continue\n",
    "        \n",
    "        larms = 0\n",
    "        uarms = 0\n",
    "        llegs = 0\n",
    "        ulegs = 0\n",
    "        avg = 0\n",
    "        for d in Humans:\n",
    "            r = pcp.evaluate(gt, d, alpha)\n",
    "            larms_ = r.lower_arms\n",
    "            uarms_ = r.upper_arms\n",
    "            ulegs_ = r.upper_legs\n",
    "            llegs_ = r.lower_legs\n",
    "            avg_ = (larms_ + uarms_ + ulegs_ + llegs_) / 4\n",
    "            if avg_ > avg:\n",
    "                avg = avg_\n",
    "                larms = larms_\n",
    "                uarms = uarms_\n",
    "                llegs = llegs_\n",
    "                ulegs = ulegs_\n",
    "        \n",
    "        L_Arms.append(larms)\n",
    "        U_Arms.append(uarms)\n",
    "        L_Legs.append(llegs)\n",
    "        U_Legs.append(ulegs)\n",
    "        Avg.append(avg)\n",
    "        GTIDs.append(gtid)\n",
    "    \n",
    "    del candidates\n",
    "    del Im\n",
    "    del Y\n",
    "    del Calib\n",
    "    \n",
    "    return L_Arms, U_Arms, L_Legs, U_Legs, Avg, GTIDs\n",
    "    \n",
    "PER_GTID = {}\n",
    "for idx, frame in enumerate(valid_frames):\n",
    "    L_Arms, U_Arms, L_Legs, U_Legs, Avg, GTIDs =\\\n",
    "        generate_pcp_score(frame)\n",
    "    \n",
    "    if len(L_Arms) > 0:\n",
    "        for gtid, larms, uarms, llegs, ulegs, avg in zip(\n",
    "            GTIDs, L_Arms, U_Arms, L_Legs, U_Legs, Avg\n",
    "        ):\n",
    "            if not gtid in PER_GTID:\n",
    "                PER_GTID[gtid] = {\n",
    "                    'larms': [],\n",
    "                    'uarms': [],\n",
    "                    'llegs': [],\n",
    "                    'ulegs': [],\n",
    "                    'avg': [],\n",
    "                    'frame': []\n",
    "                }\n",
    "            PER_GTID[gtid]['larms'].append(larms)\n",
    "            PER_GTID[gtid]['uarms'].append(uarms)\n",
    "            PER_GTID[gtid]['llegs'].append(llegs)\n",
    "            PER_GTID[gtid]['ulegs'].append(ulegs)\n",
    "            PER_GTID[gtid]['avg'].append(avg)\n",
    "            PER_GTID[gtid]['frame'].append(frame)\n",
    "            \n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mvpose.evaluation import pcp\n",
    "import mvpose.data.kth_football2 as kth\n",
    "from mvpose.algorithm.candidate_selection import project_human_to_2d\n",
    "\n",
    "#frame = valid_frames[29]\n",
    "frame = 716\n",
    "print('Frame=', frame)\n",
    "Im, Y, Calib = epfl_campus.get(root, frame)\n",
    "\n",
    "candidate_name = candidate_main_name + str(frame) + \".npy\"\n",
    "candidate_name = join(tmp, candidate_name)\n",
    "assert isfile(candidate_name)\n",
    "candidates = np.load(candidate_name)\n",
    "Humans = kth.transform3d_from_mscoco(candidates)\n",
    "\n",
    "fig = plt.figure(figsize=(16,10))\n",
    "\n",
    "GT_COLORS = ['blue', 'green', 'red']\n",
    "\n",
    "for cid ,(im, cam) in enumerate(zip(Im, Calib)):\n",
    "    ax = fig.add_subplot(1, 3, cid+1)\n",
    "    ax.axis('off')\n",
    "    ax.imshow(im)\n",
    "    for human in Humans:\n",
    "        human2d = project_human_to_2d(human, cam)\n",
    "        for pt2d in human2d:\n",
    "            if pt2d is None:\n",
    "                continue\n",
    "            x, y = pt2d\n",
    "            ax.scatter(x, y, color='black')\n",
    "        \n",
    "    for gtid, gt in enumerate(Y):\n",
    "        if gt is None:\n",
    "            continue\n",
    "        gt2d = cam.projectPoints(gt)\n",
    "        for x, y in gt2d:\n",
    "            ax.scatter(x, y, color=GT_COLORS[gtid], alpha=0.5)\n",
    "\n",
    "\n",
    "            \n",
    "print('PCP:')\n",
    "L_Arms, U_Arms, L_Legs, U_Legs, Avg, GTIDs = generate_pcp_score(frame)\n",
    "for gtid, larms, uarms, llegs, ulegs, avg in zip(\n",
    "        GTIDs, L_Arms, U_Arms, L_Legs, U_Legs, Avg\n",
    "    ):\n",
    "    print('  gtid =', gtid)\n",
    "    print('\\tlarms =', larms)\n",
    "    print('\\tuarms =', uarms)\n",
    "    print('\\tllegs =', llegs)\n",
    "    print('\\tulegs =', ulegs)\n",
    "    print('\\tavg =', avg)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def plot_human(ax, human, color):\n",
    "    for pt3d in human:\n",
    "        if pt3d is None:\n",
    "            continue\n",
    "        ax.scatter(pt3d[0], pt3d[1], pt3d[2], color=color)\n",
    "        \n",
    "    \n",
    "    limbs = [\n",
    "        (0, 1), (1, 2), (2, 3), (3, 4), (4, 5),\n",
    "        (6, 7), (7, 8), (8, 9), (9, 10), (10, 11),\n",
    "        (8, 12), (9, 12), (8, 9), (12, 13),\n",
    "        (2, 8), (3, 9)\n",
    "    ]\n",
    "    \n",
    "    for a, b in limbs:\n",
    "        ptA = human[a]\n",
    "        ptB = human[b]\n",
    "        if ptA is None or ptB is None:\n",
    "            continue\n",
    "        x1, y1, z1 = ptA\n",
    "        x2, y2, z2 = ptB\n",
    "        ax.plot([x1, x2], [y1, y2], [z1, z2], color=color)\n",
    "\n",
    "\n",
    "gts = []\n",
    "for gt in Y:\n",
    "    if gt is None:\n",
    "        continue\n",
    "    else:\n",
    "        gts.append(gt)\n",
    "count_gt = len(gts)\n",
    "        \n",
    "fig = plt.figure(figsize=(16, 10 * count_gt))\n",
    "\n",
    "def plot_all(ax, current_gt):\n",
    "    mx, my, _ = np.mean(current_gt, axis=0)\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_zlim([0, 2])\n",
    "    ax.set_xlim([mx - 0.5, mx + 0.5])\n",
    "    ax.set_ylim([my - 0.5, my + 0.5])\n",
    "    #ax.axis('off')\n",
    "\n",
    "    for d in Humans:\n",
    "        plot_human(ax, d, 'black')\n",
    "    for gtid, gt in enumerate(Y):\n",
    "        if not gt is None:\n",
    "            plot_human(ax, gt, GT_COLORS[gtid])\n",
    "\n",
    "if count_gt > 0:\n",
    "    \n",
    "    for idx, current_gt in enumerate(gts):\n",
    "        ax = fig.add_subplot(count_gt, 3, (3*idx)+1, projection='3d')\n",
    "        plot_all(ax, current_gt)\n",
    "        \n",
    "        ax = fig.add_subplot(count_gt, 3, (3*idx)+2, projection='3d')\n",
    "        ax.view_init(elev=10., azim=0)\n",
    "        plot_all(ax, current_gt)\n",
    "        \n",
    "        ax = fig.add_subplot(count_gt, 3, (3*idx)+3, projection='3d')\n",
    "        ax.view_init(elev=10., azim=90)\n",
    "        plot_all(ax, current_gt)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "# # -- find best pcp combinations\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gtid, data in PER_GTID.items():\n",
    "    print(\"hid:\", gtid)\n",
    "    print('larms:\\t', np.mean(PER_GTID[gtid]['larms']))\n",
    "    print('uarms:\\t', np.mean(PER_GTID[gtid]['uarms']))\n",
    "    print('llegs:\\t', np.mean(PER_GTID[gtid]['llegs']))\n",
    "    print('ulegs:\\t', np.mean(PER_GTID[gtid]['ulegs']))\n",
    "    print('avg:\\t', np.mean(PER_GTID[gtid]['avg']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD RESULTS\n",
    "\n",
    "# hid: 1\n",
    "# larms:\t 0.6090425531914894\n",
    "# uarms:\t 0.9813829787234043\n",
    "# llegs:\t 0.9973404255319149\n",
    "# ulegs:\t 1.0\n",
    "# avg:\t 0.8969414893617021\n",
    "# hid: 2\n",
    "# larms:\t 0.6360294117647058\n",
    "# uarms:\t 0.8860294117647058\n",
    "# llegs:\t 0.9816176470588235\n",
    "# ulegs:\t 0.9816176470588235\n",
    "# avg:\t 0.8713235294117647\n",
    "# hid: 0\n",
    "# larms:\t 0.5625\n",
    "# uarms:\t 0.7291666666666666\n",
    "# llegs:\t 1.0\n",
    "# ulegs:\t 1.0\n",
    "# avg:\t 0.8229166666666666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid = 2\n",
    "larms = PER_GTID[pid]['larms']\n",
    "uarms = PER_GTID[pid]['uarms']\n",
    "llegs = PER_GTID[pid]['llegs']\n",
    "ulegs = PER_GTID[pid]['ulegs']\n",
    "avgs = PER_GTID[pid]['avg']\n",
    "frames = PER_GTID[pid]['frame']\n",
    "\n",
    "fig = plt.figure(figsize=(16,10))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot(range(len(larms)), larms, label='larms', alpha=0.3)\n",
    "ax.plot(range(len(larms)), uarms, label='uarms', alpha=0.3)\n",
    "ax.plot(range(len(larms)), llegs, label='llegs', alpha=0.3)\n",
    "ax.plot(range(len(larms)), ulegs, label='ulegs', alpha=0.3)\n",
    "ax.plot(range(len(larms)), avgs, label='avg')\n",
    "\n",
    "loc = 102\n",
    "\n",
    "print(\"FRAME=\", frames[loc])\n",
    "print('AVG=', avgs[loc])\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# competition\n",
    "Actor0 = [\n",
    "    .9655,  # uarms\n",
    "    .8621,  # larms\n",
    "    .9310,  # ulegs\n",
    "    .9655   # llegs\n",
    "]\n",
    "Actor1 = [.9735, .4294, .75, .8941]\n",
    "Actor2 = [.8981, .7476, .9175, .7621]\n",
    "\n",
    "for Actor in [Actor0, Actor1, Actor2]:\n",
    "    print(np.mean(Actor))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
