{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julian/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMPM\n",
      "loading settings: 0.0005092620849609375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2437, 486, 644, 3)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# ---- settings ----\n",
    "import json\n",
    "Settings = json.load(open('../settings.txt'))\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sys\n",
    "sys.path.insert(0, '../'); sys.path.insert(0, '../samples')\n",
    "import paf_loader\n",
    "from os.path import join, isdir, isfile\n",
    "import numpy as np\n",
    "import cv2\n",
    "from cselect import color as cs\n",
    "from time import time\n",
    "from reid import reid\n",
    "\n",
    "from mvpose.data import umpm\n",
    "from mvpose.algorithm.settings import get_settings, get_tracking_settings\n",
    "\n",
    "root = join(Settings['data_root'], 'pak')\n",
    "user = Settings['UMPM']['username']\n",
    "pwd = Settings['UMPM']['password']\n",
    "tmp = Settings['tmp']\n",
    "\n",
    "_start = time()\n",
    "X, Y, Calib = umpm.get(root, 'p2_free_1', user, pwd)\n",
    "\n",
    "# --- Things that kinda have to be parametrized ---\n",
    "#candidate_main_name = 'umpm_ms60_candidates_frame'\n",
    "candidate_main_name = 'umpm_ms60_candidates_no_unary_frame'\n",
    "dict_file = join(tmp, 'scores_s60_umpm_overfit.npy')\n",
    "params = get_settings(ms_radius=60)\n",
    "# -------------------------------------------------\n",
    "\n",
    "_start = time()\n",
    "\n",
    "#reid_model = reid.ReId(\n",
    "#    url='http://188.138.127.15:81/models/model_heavy_umpm.h5',\n",
    "#    name='model_heavy_umpm.h5')\n",
    "reid_model = {}  # we can skip this ONLY if we already calc. reid scores!\n",
    "tracking_params = get_tracking_settings(params, \n",
    "                                        low_spec_mode=True, \n",
    "                                        reid_model=reid_model,\n",
    "                                        personreid_batchsize=2)\n",
    "_end = time()\n",
    "print(\"loading settings:\", _end - _start)\n",
    "def get_track(FRAMES):\n",
    "    Ims = []\n",
    "    Hms = []\n",
    "    Pafs = []\n",
    "    \n",
    "    im_name = 'umpm_f' + '_'.join([str(s) for s in FRAMES]) + 'im.npy'\n",
    "    hm_name = 'umpm_f' + '_'.join([str(s) for s in FRAMES]) + 'hm.npy'\n",
    "    pf_name = 'umpm_f' + '_'.join([str(s) for s in FRAMES]) + 'pf.npy'\n",
    "    im_name = join(tmp, im_name)\n",
    "    hm_name = join(tmp, hm_name)\n",
    "    pf_name = join(tmp, pf_name)\n",
    "    \n",
    "    if isfile(im_name) and isfile(hm_name) and isfile(pf_name):\n",
    "        Ims = np.load(im_name)\n",
    "        Hms = np.load(hm_name)\n",
    "        Pafs = np.load(pf_name)\n",
    "    else:\n",
    "        for frame in FRAMES:\n",
    "            print('load frame ', frame)\n",
    "            Im = np.array([X[0][frame], X[1][frame], X[2][frame], X[3][frame]])\n",
    "            Ims.append(Im)\n",
    "            heatmaps, pafs = paf_loader.load_confidence_map_and_paf('umpm', \n",
    "                                                                Im, \n",
    "                                                                frame, \n",
    "                                                                dir=tmp)\n",
    "            Hms.append(heatmaps)\n",
    "            Pafs.append(pafs)\n",
    "\n",
    "        Ims = np.array(Ims)\n",
    "        Hms = np.array(Hms)\n",
    "        Pafs = np.array(Pafs)\n",
    "        np.save(im_name, Ims)\n",
    "        np.save(hm_name, Hms)\n",
    "        np.save(pf_name, Pafs)\n",
    "        \n",
    "    return Ims, Hms, Pafs\n",
    "\n",
    "X[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: pre-load pafs and heatmaps\n",
    "(my laptop 'sucks' so I need to pre-load the pafs and heatmaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load(FRAMES):\n",
    "#     for frame in FRAMES:\n",
    "#         print('handle frame ', frame)\n",
    "#         Im = np.array([X[0][frame], X[1][frame], X[2][frame], X[3][frame]])\n",
    "#         heatmaps, pafs = paf_loader.load_confidence_map_and_paf('umpm', \n",
    "#                                                             Im, \n",
    "#                                                             frame, \n",
    "#                                                             dir=tmp)\n",
    "#         del heatmaps\n",
    "#         del pafs\n",
    "#         del Im\n",
    "\n",
    "# def qq():\n",
    "#     for i in range(45, 2500, 60):\n",
    "#         FRAMES = list(range(i, i+60, 30))\n",
    "#         print('frames:', FRAMES)\n",
    "#         _start = time()\n",
    "#         load(FRAMES)\n",
    "#         _end = time()\n",
    "#         print('\\telapsed', _end - _start)\n",
    "\n",
    "# qq()  # \"memory-efficient\" way of loading the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: generate candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mvpose import pose\n",
    "# from mvpose.algorithm import graphcut\n",
    "\n",
    "# def execute(FRAME):\n",
    "\n",
    "#     Im = np.array([X[0][FRAME], X[1][FRAME], X[2][FRAME], X[3][FRAME]])\n",
    "\n",
    "#     print('\\nframe:', FRAME)\n",
    "#     heatmaps, pafs = paf_loader.load_confidence_map_and_paf('umpm', \n",
    "#                                                             Im, \n",
    "#                                                             FRAME, \n",
    "#                                                             dir=tmp)\n",
    "#     _start = time()\n",
    "#     detections = pose.estimate_heuristic(\n",
    "#         Calib, heatmaps, pafs, settings=params, \n",
    "#         debug=False, use_greedy=False)\n",
    "#     _end = time()\n",
    "#     print('total elapsed:', _end - _start)\n",
    "    \n",
    "#     # -- store to file --\n",
    "#     candidate_name = candidate_main_name + str(FRAME) + \".npy\"\n",
    "#     candidate_name = join(tmp, candidate_name)\n",
    "#     np.save(candidate_name, detections)\n",
    "    \n",
    "#     del heatmaps\n",
    "#     del pafs\n",
    "#     del detections\n",
    "\n",
    "# def run_all():\n",
    "#     # go to 2500\n",
    "#     for i in range(2430, 2500, 60):\n",
    "#         FRAMES = list(range(i, i+60, 30))\n",
    "#         for f in FRAMES:\n",
    "#             execute(f)\n",
    "\n",
    "# run_all()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: calculate re-id score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame  0\n",
      "frame  300\n",
      "frame  600\n",
      "frame  900\n",
      "frame  1200\n",
      "frame  1500\n",
      "frame  1800\n",
      "frame  2100\n",
      "frame  2400\n",
      "82\n"
     ]
    }
   ],
   "source": [
    "from mvpose.algorithm.track_graph_partitioning import get_bb, distance3d_humans, ValidImageCandidateExtractor\n",
    "from mvpose.tracking import extend_calibration_to_frames\n",
    "\n",
    "n_frames = 2437\n",
    "graph_3d = {}\n",
    "human_candidates = []\n",
    "Im = []\n",
    "for frame in range(0, n_frames, 30):\n",
    "    if frame % 300 == 0:\n",
    "        print('frame ', frame)\n",
    "    candidate_name = candidate_main_name + str(frame) + \".npy\"\n",
    "    candidate_name = join(tmp, candidate_name)\n",
    "    assert isfile(candidate_name)\n",
    "    Humans = np.load(candidate_name)\n",
    "    human_candidates.append(Humans)\n",
    "    im = np.array([X[0][frame], X[1][frame], X[2][frame], X[3][frame]], 'uint8')\n",
    "    Im.append(im)\n",
    "Im = np.array(Im, 'uint8')\n",
    "\n",
    "print(len(human_candidates))\n",
    "\n",
    "Calibs = extend_calibration_to_frames([Calib], n_frames)\n",
    "\n",
    "img_cand = ValidImageCandidateExtractor(\n",
    "    Im, human_candidates, Calibs, tracking_params)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# n = len(img_cand.ImgsA)\n",
    "# start = 0\n",
    "# if isfile(dict_file):\n",
    "#     start = np.load(dict_file).item()['next_frame']\n",
    "\n",
    "# print('start:' + str(start) + ' until ' + str(n))\n",
    "# for frame in range(start, n):\n",
    "#     if isfile(dict_file):\n",
    "#         storage = np.load(dict_file).item()\n",
    "#     else:\n",
    "#         storage = {}\n",
    "    \n",
    "#     if frame % 10 == 0:\n",
    "#         print('frame %05d/' % (frame+1) + str(n))\n",
    "#         _start = time()\n",
    "#     A = img_cand.ImgsA[frame]\n",
    "#     B = img_cand.ImgsB[frame]\n",
    "#     score = np.squeeze(reid_model.predict(A, B))\n",
    "#     #print('storage', storage)\n",
    "#     #print('score', score)\n",
    "#     storage[frame] = score\n",
    "#     storage['next_frame'] = frame + 1\n",
    "#     np.save(dict_file, storage)\n",
    "#     if frame % 10 == 0:\n",
    "#         _end = time()\n",
    "#         print('\\telapsed', _end - _start)\n",
    "#     del storage\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: build graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mvpose.algorithm.track_graph_partitioning import generate_graph3d, GraphSolver\n",
    "# from mvpose.algorithm.track_graph_partitioning import construct_query_graph\n",
    "# from mvpose.tracking import extract_tracks\n",
    "\n",
    "# storage = np.load(dict_file).item()\n",
    "\n",
    "# scores = []\n",
    "# pairs = img_cand.pairs\n",
    "# n = len(img_cand.ImgsA)\n",
    "# print(n)\n",
    "\n",
    "# assert(len(pairs) == n)\n",
    "# for frame in range(n):\n",
    "#     scores.append(storage[frame])\n",
    "# assert len(scores) == n\n",
    "\n",
    "\n",
    "# graph_3d = generate_graph3d(scores, pairs)  # t1, pid1, t2, pid2\n",
    "\n",
    "# n_frames_red = len(human_candidates)\n",
    "# graph_partitioning = GraphSolver(graph_3d, \n",
    "#                                  n_frames_red,\n",
    "#                                  tracking_params.T)\n",
    "\n",
    "\n",
    "# G = construct_query_graph(graph_partitioning, n_frames_red)\n",
    "\n",
    "# tracks = extract_tracks(human_candidates, G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from pak.evaluation import MOTA\n",
    "\n",
    "# from mvpose.tracking import extract_tracks\n",
    "\n",
    "# tracks = extract_tracks(human_candidates, G)\n",
    "\n",
    "# # right food: own dataset: 13, mscoco: 10\n",
    "# # left foot: own dataset 10, mscoco: 13\n",
    "\n",
    "# GT_jid = 13  # 0 ... 13\n",
    "# HY_jid = 10  # 0 ... 17\n",
    "\n",
    "# Gt = []\n",
    "# Hy = []\n",
    "# for loc_frame, frame in enumerate(range(0, n_frames, 30)):\n",
    "#     # === ground truth ===\n",
    "#     y = Y[frame]\n",
    "#     pid1 = 0\n",
    "#     p1 = y[GT_jid, 0:3]\n",
    "#     pid2 = 1\n",
    "#     p2 = y[GT_jid+14, 0:3]\n",
    "#     Gt.append((loc_frame, pid1, *p1))\n",
    "#     Gt.append((loc_frame, pid2, *p2))\n",
    "    \n",
    "#     # === hypothesis ===\n",
    "#     for loc, human in enumerate(human_candidates[loc_frame]):\n",
    "#         pt = human[HY_jid]\n",
    "#         pid = tracks[loc_frame][loc]\n",
    "#         if pt is not None:\n",
    "#             Hy.append((loc_frame, pid, *pt))\n",
    "    \n",
    "    \n",
    "# # print(Hy)\n",
    "# # print('--')\n",
    "# # print(Gt)\n",
    "# Hy = np.array(Hy)\n",
    "# Gt = np.array(Gt)\n",
    "\n",
    "# threshold = 150\n",
    "# # result is a scalar value in the range of [-infinity, 1)\n",
    "# mota, info, debug = MOTA.evaluate(Gt, Hy, threshold, info=True, \n",
    "#                            debug_info=True)\n",
    "\n",
    "# print('MOTA', mota)\n",
    "# print('info', info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCP score calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mvpose.evaluation import pcp\n",
    "import mvpose.data.kth_football2 as kth\n",
    "import mvpose.data.skeleton_augmentation as ska\n",
    "model_path = '../data/model_poseprediction.h5'\n",
    "gen = ska.LimbGenerator(model_path, params.scale_to_mm)\n",
    "\n",
    "def generate_pcp_score(frame):\n",
    "    alpha = 0.5\n",
    "    candidate_name = candidate_main_name + str(frame) + \".npy\"\n",
    "    candidate_name = join(tmp, candidate_name)\n",
    "    assert isfile(candidate_name)\n",
    "    candidates = np.load(candidate_name)\n",
    "    candidates = gen.apply(candidates)\n",
    "    Humans = kth.transform3d_from_mscoco(candidates)\n",
    "    \n",
    "    #Im, Y, Calib = epfl_campus.get(root, frame)\n",
    "    \n",
    "    L_Arms = []\n",
    "    U_Arms = []\n",
    "    L_Legs = []\n",
    "    U_Legs = []\n",
    "    Avg = []\n",
    "    GTIDs = []\n",
    "  \n",
    "    \n",
    "    a = Y[frame,0:14,0:3]\n",
    "    b = Y[frame,14:,0:3]\n",
    "    \n",
    "    Y_ = kth.transform3d_from_umpm([a, b])\n",
    "\n",
    "    for gtid, gt in enumerate(Y_):\n",
    "        if gt is None:\n",
    "            continue\n",
    "        \n",
    "        larms = 0\n",
    "        uarms = 0\n",
    "        llegs = 0\n",
    "        ulegs = 0\n",
    "        avg = 0\n",
    "        for d in Humans:\n",
    "            r = pcp.evaluate(gt, d, alpha)\n",
    "            larms_ = r.lower_arms\n",
    "            uarms_ = r.upper_arms\n",
    "            ulegs_ = r.upper_legs\n",
    "            llegs_ = r.lower_legs\n",
    "            avg_ = (larms_ + uarms_ + ulegs_ + llegs_) / 4\n",
    "            if avg_ > avg:\n",
    "                avg = avg_\n",
    "                larms = larms_\n",
    "                uarms = uarms_\n",
    "                llegs = llegs_\n",
    "                ulegs = ulegs_\n",
    "        \n",
    "        L_Arms.append(larms)\n",
    "        U_Arms.append(uarms)\n",
    "        L_Legs.append(llegs)\n",
    "        U_Legs.append(ulegs)\n",
    "        Avg.append(avg)\n",
    "        GTIDs.append(gtid)\n",
    "    \n",
    "    del candidates\n",
    "    #del Im\n",
    "    #del Y\n",
    "    #del Calib\n",
    "    return L_Arms, U_Arms, L_Legs, U_Legs, Avg, GTIDs\n",
    "\n",
    "\n",
    "PER_GTID = {}\n",
    "\n",
    "n_frames = 2437\n",
    "for frame in range(0, n_frames, 30):\n",
    "    L_Arms, U_Arms, L_Legs, U_Legs, Avg, GTIDs =\\\n",
    "        generate_pcp_score(frame)\n",
    "    \n",
    "    if len(L_Arms) > 0:\n",
    "        for gtid, larms, uarms, llegs, ulegs, avg in zip(\n",
    "            GTIDs, L_Arms, U_Arms, L_Legs, U_Legs, Avg\n",
    "        ):\n",
    "            if not gtid in PER_GTID:\n",
    "                PER_GTID[gtid] = {\n",
    "                    'larms': [],\n",
    "                    'uarms': [],\n",
    "                    'llegs': [],\n",
    "                    'ulegs': [],\n",
    "                    'avg': [],\n",
    "                    'frame': []\n",
    "                }\n",
    "            PER_GTID[gtid]['larms'].append(larms)\n",
    "            PER_GTID[gtid]['uarms'].append(uarms)\n",
    "            PER_GTID[gtid]['llegs'].append(llegs)\n",
    "            PER_GTID[gtid]['ulegs'].append(ulegs)\n",
    "            PER_GTID[gtid]['avg'].append(avg)\n",
    "            PER_GTID[gtid]['frame'].append(frame)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid= 0\n",
      "\tuarms: 0.975609756097561\n",
      "\tlarms: 0.9634146341463414\n",
      "\tulegs: 1.0\n",
      "\tllegs: 1.0\n",
      "\tavg  : 0.9847560975609756\n",
      "pid= 1\n",
      "\tuarms: 0.975609756097561\n",
      "\tlarms: 0.9207317073170732\n",
      "\tulegs: 0.9939024390243902\n",
      "\tllegs: 0.9939024390243902\n",
      "\tavg  : 0.9710365853658537\n"
     ]
    }
   ],
   "source": [
    "for pid in PER_GTID.keys():\n",
    "    print('pid=', pid)\n",
    "    \n",
    "    print('\\tuarms:', np.mean(PER_GTID[pid]['uarms']))\n",
    "    print('\\tlarms:', np.mean(PER_GTID[pid]['larms']))\n",
    "    print('\\tulegs:', np.mean(PER_GTID[pid]['ulegs']))\n",
    "    print('\\tllegs:', np.mean(PER_GTID[pid]['llegs']))\n",
    "    print('\\tavg  :', np.mean(PER_GTID[pid]['avg']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
