{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMPM\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# ---- settings ----\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import isfile\n",
    "import sys\n",
    "from time import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os.path import join, isdir\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "sys.path.insert(0,'../')\n",
    "sys.path.append('./../../easy_multi_person_pose_estimation')\n",
    "from mvpose import pose\n",
    "from poseestimation import model\n",
    "pe = model.PoseEstimator()\n",
    "import mvpose.data.transform as tfm\n",
    "\n",
    "Settings = json.load(open('../settings.txt'))\n",
    "\n",
    "root = join(Settings['data_root'], 'pak')\n",
    "\n",
    "from pak.datasets.UMPM import UMPM\n",
    "user = Settings['UMPM']['username']\n",
    "pwd = Settings['UMPM']['password']\n",
    "\n",
    "\n",
    "X, Y, Calib = tfm.get_from_umpm(root, 'p2_free_1', user, pwd)\n",
    "\n",
    "# create video\n",
    "start_frame = 0\n",
    "skip = 50\n",
    "total_frames = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handling frame  0\n",
      "frame0000.png\n",
      "handling frame  50\n",
      "frame0050.png\n",
      "handling frame  100\n",
      "frame0100.png\n",
      "handling frame  150\n",
      "frame0150.png\n",
      "handling frame  200\n",
      "frame0200.png\n",
      "handling frame  250\n",
      "frame0250.png\n",
      "handling frame  300\n",
      "frame0300.png\n",
      "handling frame  350\n",
      "frame0350.png\n",
      "handling frame  400\n",
      "frame0400.png\n",
      "handling frame  450\n",
      "frame0450.png\n"
     ]
    }
   ],
   "source": [
    "from mvpose.pose import estimate\n",
    "\n",
    "for f in range(start_frame, (start_frame + total_frames) * skip, skip):\n",
    "    \n",
    "    print('handling frame ', f)\n",
    "    \n",
    "#     Im = np.array([X[0][f], X[1][f], X[2][f], X[3][f]])\n",
    "    \n",
    "#     _start = time()\n",
    "#     heatmaps, pafs = pe.predict_pafs_and_heatmaps(Im)\n",
    "#     _end = time(); print('elapsed:', _end - _start)\n",
    "    \n",
    "#     humans = estimate(Calib, heatmaps, pafs)\n",
    "    \n",
    "    fname = 'frame%04d.png' % (f,)\n",
    "    print(fname)\n",
    "    \n",
    "    \n",
    "#     fig = plt.figure(figsize=(20, 10))\n",
    "#     fig.add_subplot(221).imshow(Im[0])\n",
    "#     fig.add_subplot(222).imshow(Im[1])\n",
    "#     fig.add_subplot(223).imshow(Im[2])\n",
    "#     fig.add_subplot(224).imshow(Im[3])\n",
    "    \n",
    "    \n",
    "#     plt.savefig('frame'+str(f) + '.png', format='png')\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
